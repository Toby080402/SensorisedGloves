# Machine-Learned Piezoresistive Sensors for Bilingual Sign Language Detection
Contains all relevant files for work completed throughout my MECH0020 third year individual project (dissertation).

The first folder contains all work related to Python and Jupyter notebook scripts. Archive contains files of data and plots created to aid visualise and test things throughout the project. Other folders contain trained models and images of various confusion matrices and relevant plots. All ML models are shown in Notebooks, and there are also Python scripts for live recognition using trained models, recording reproducibility tests, collecting data for ML, and plotting learning curves.

Other folders consist of code along with Excel data used to form the various plots throughout the report, and some extra ones for different tests completed. The data file contains a folder with all final datasets used to train the ML algorithm, which is a total of 6 .csv files. It also contains pdf images of every gesture made, which consists of an average of the 10 signals with error bars showing the standard deviation. 

Finally, the 'Live Recognition Recording.mp4' file contains the video referenced in the report in Section 5.4: Live Recognition. This shows the live recognition script in use with the FlexiForce A201 sensorised glove. 
